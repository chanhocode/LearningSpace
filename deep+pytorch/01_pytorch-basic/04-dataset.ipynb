{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset & Dataloader\n",
    "> 데이터세트는 데이터의 집합을 의미하며, 입력값(X)와 결과값(Y)에 대한 정보를 제공하거나 일련의 데이터 묶음을 제공한다.\n",
    "\n",
    "## 데이터세트 클래스 기본형\n",
    "\n",
    "- 초기화 메서드( __init__ ): 입력된 데이터의 전처리 과정을 수행\n",
    "\n",
    "- 호출 메서드( __getitem__ ): 학습을 진행할 때 사용되는 하나의 행을 불러오는 과정\n",
    "\n",
    "- 길이 반환 메서드( __len__ ): 학습에 사용된 전체 데이터세트의 개수를 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "  def __init__(self, data, *arg, **kwargs):\n",
    "    self.data = data\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    return tuple(data[index] for data in data.tensor)\n",
    "  \n",
    "  def __len__(self):\n",
    "    return self.data[0].size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader\n",
    "> Dataset에 저장된 데이터를 어떠한 방식으로 불러와 활용할지 정의한다.\n",
    "\n",
    "### 제공\n",
    "- 배치 크기(batch_size): 학습에 사용되는 데이터의 개수가 많이 한 번의 엑포에서 모든 데이터를 메모리에 올릴 수 없을 때 데이터를 나누는 역할을 수행한다.\n",
    "- 데이터 순서 변경(shuffle): 모델이 데이터 간의 관계가 아닌, 데이터의 순서로 학습되는 것을 방지하고자 수행\n",
    "- 데이터 로드 프로세스 수(num_workers): 데이터를 불러올 때 사용할 프로세스의 개수를 의미한다.\n",
    "\n",
    "## 다중 선형 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 | Model [Parameter containing:\n",
      "tensor([[0.5873, 0.1982],\n",
      "        [0.6323, 0.5959]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.5168, -0.0938], requires_grad=True)] | Cost: 0.031\n",
      "Epoch 2000 | Model [Parameter containing:\n",
      "tensor([[0.7035, 0.1382],\n",
      "        [0.7052, 0.5582]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.6929, -0.2043], requires_grad=True)] | Cost: 0.008\n",
      "Epoch 3000 | Model [Parameter containing:\n",
      "tensor([[0.7627, 0.1076],\n",
      "        [0.7423, 0.5390]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.7827, -0.2606], requires_grad=True)] | Cost: 0.002\n",
      "Epoch 4000 | Model [Parameter containing:\n",
      "tensor([[0.7928, 0.0921],\n",
      "        [0.7613, 0.5293]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8284, -0.2893], requires_grad=True)] | Cost: 0.001\n",
      "Epoch 5000 | Model [Parameter containing:\n",
      "tensor([[0.8082, 0.0841],\n",
      "        [0.7709, 0.5243]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8517, -0.3039], requires_grad=True)] | Cost: 0.000\n",
      "Epoch 6000 | Model [Parameter containing:\n",
      "tensor([[0.8160, 0.0801],\n",
      "        [0.7758, 0.5217]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8636, -0.3114], requires_grad=True)] | Cost: 0.000\n",
      "Epoch 7000 | Model [Parameter containing:\n",
      "tensor([[0.8200, 0.0780],\n",
      "        [0.7783, 0.5204]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8696, -0.3152], requires_grad=True)] | Cost: 0.000\n",
      "Epoch 8000 | Model [Parameter containing:\n",
      "tensor([[0.8220, 0.0770],\n",
      "        [0.7796, 0.5198]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8727, -0.3171], requires_grad=True)] | Cost: 0.000\n",
      "Epoch 9000 | Model [Parameter containing:\n",
      "tensor([[0.8230, 0.0764],\n",
      "        [0.7802, 0.5195]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8742, -0.3181], requires_grad=True)] | Cost: 0.000\n",
      "Epoch 10000 | Model [Parameter containing:\n",
      "tensor([[0.8236, 0.0762],\n",
      "        [0.7805, 0.5193]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8750, -0.3186], requires_grad=True)] | Cost: 0.000\n",
      "Epoch 11000 | Model [Parameter containing:\n",
      "tensor([[0.8238, 0.0760],\n",
      "        [0.7807, 0.5192]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8755, -0.3188], requires_grad=True)] | Cost: 0.000\n",
      "Epoch 12000 | Model [Parameter containing:\n",
      "tensor([[0.8240, 0.0760],\n",
      "        [0.7808, 0.5192]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8757, -0.3190], requires_grad=True)] | Cost: 0.000\n",
      "Epoch 13000 | Model [Parameter containing:\n",
      "tensor([[0.8240, 0.0759],\n",
      "        [0.7808, 0.5191]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8758, -0.3190], requires_grad=True)] | Cost: 0.000\n",
      "Epoch 14000 | Model [Parameter containing:\n",
      "tensor([[0.8241, 0.0759],\n",
      "        [0.7809, 0.5191]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8758, -0.3191], requires_grad=True)] | Cost: 0.000\n",
      "Epoch 15000 | Model [Parameter containing:\n",
      "tensor([[0.8241, 0.0759],\n",
      "        [0.7809, 0.5191]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8758, -0.3191], requires_grad=True)] | Cost: 0.000\n",
      "Epoch 16000 | Model [Parameter containing:\n",
      "tensor([[0.8241, 0.0759],\n",
      "        [0.7809, 0.5191]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8758, -0.3191], requires_grad=True)] | Cost: 0.000\n",
      "Epoch 17000 | Model [Parameter containing:\n",
      "tensor([[0.8241, 0.0759],\n",
      "        [0.7809, 0.5191]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8758, -0.3191], requires_grad=True)] | Cost: 0.000\n",
      "Epoch 18000 | Model [Parameter containing:\n",
      "tensor([[0.8241, 0.0759],\n",
      "        [0.7809, 0.5191]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8758, -0.3191], requires_grad=True)] | Cost: 0.000\n",
      "Epoch 19000 | Model [Parameter containing:\n",
      "tensor([[0.8241, 0.0759],\n",
      "        [0.7809, 0.5191]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8758, -0.3191], requires_grad=True)] | Cost: 0.000\n",
      "Epoch 20000 | Model [Parameter containing:\n",
      "tensor([[0.8241, 0.0759],\n",
      "        [0.7809, 0.5191]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8758, -0.3191], requires_grad=True)] | Cost: 0.000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_x = torch.FloatTensor([\n",
    "  [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7]\n",
    "])\n",
    "train_y = torch.FloatTensor([\n",
    "  [0.1, 1.5], [1, 2.8], [1.9, 4.1], [2.8, 5.4], [3.7, 6.7], [4.6, 8]\n",
    "])\n",
    "\n",
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "train_dataLoader = DataLoader(train_dataset, batch_size = 2, shuffle= True, drop_last= True)\n",
    "# drop_last = True : 배치 크기에 맞지 않는 배치를 제거한다. 예를 들어, 데이터세트의 크기가 5일 때, 배치사이즈가 2라면 마지막 배치의 크기는 1이 된다. 1인 마지막 배치를 학습에 포함시키지 않는다.\n",
    "\n",
    "# 모델, 오차함수, 최적화 선언\n",
    "model = nn.Linear(2, 2, bias = True)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001)\n",
    "\n",
    "# 데이터로더 적용\n",
    "for epoch in range(20000):\n",
    "  cost = 0.0\n",
    "  \n",
    "  for batch in train_dataLoader:\n",
    "    x, y = batch\n",
    "    output = model(x)\n",
    "    \n",
    "    loss = criterion(output, y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    cost += loss\n",
    "  \n",
    "  cost = cost / len(train_dataLoader)\n",
    "  \n",
    "  if(epoch + 1) % 1000 == 0:\n",
    "    print(f'Epoch {epoch + 1:4d} | Model {list(model.parameters())} | Cost: {cost:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 / 데이터세트 분리\n",
    "\n",
    "## 모듈 클래스\n",
    "> 초기화 메서드와 순방향 메서드를 재정의하여 활용한다. 초기화 메서드는 신경망에 사용될 계층을 초기화하고, 순방향 메서드에서는 모델이 어떤 구조를 갖게 될지를 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 클래스 기본형\n",
    "class Model(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__() # 모듈 클래스의 속성을 초기화\n",
    "    self.conv1 = nn.Conv2d(1, 20, 5)\n",
    "    self.conv2 = nn.Conv2d(20, 20, 5)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.conv1(x))\n",
    "    x = F.relu(self.conv2(x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1000, model : [Parameter containing:\n",
      "tensor([[ 3.1064, -1.7001]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.1082], device='mps:0', requires_grad=True)], cost: 0.142\n",
      "epoch: 2000, model : [Parameter containing:\n",
      "tensor([[ 3.1058, -1.7030]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.1411], device='mps:0', requires_grad=True)], cost: 0.136\n",
      "epoch: 3000, model : [Parameter containing:\n",
      "tensor([[ 3.1056, -1.7028]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.1711], device='mps:0', requires_grad=True)], cost: 0.118\n",
      "epoch: 4000, model : [Parameter containing:\n",
      "tensor([[ 3.1051, -1.7028]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.1986], device='mps:0', requires_grad=True)], cost: 0.108\n",
      "epoch: 5000, model : [Parameter containing:\n",
      "tensor([[ 3.1043, -1.7029]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.2237], device='mps:0', requires_grad=True)], cost: 0.102\n",
      "epoch: 6000, model : [Parameter containing:\n",
      "tensor([[ 3.1039, -1.7032]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.2468], device='mps:0', requires_grad=True)], cost: 0.104\n",
      "epoch: 7000, model : [Parameter containing:\n",
      "tensor([[ 3.1035, -1.7031]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.2677], device='mps:0', requires_grad=True)], cost: 0.095\n",
      "epoch: 8000, model : [Parameter containing:\n",
      "tensor([[ 3.1035, -1.7029]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.2870], device='mps:0', requires_grad=True)], cost: 0.096\n",
      "epoch: 9000, model : [Parameter containing:\n",
      "tensor([[ 3.1028, -1.7029]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.3046], device='mps:0', requires_grad=True)], cost: 0.097\n",
      "epoch: 10000, model : [Parameter containing:\n",
      "tensor([[ 3.1027, -1.7031]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.3208], device='mps:0', requires_grad=True)], cost: 0.083\n"
     ]
    }
   ],
   "source": [
    "# 비선형 회귀\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    self.x = df.iloc[:, 0].values\n",
    "    self.y = df.iloc[:, 1].values\n",
    "    self.length = len(df)\n",
    "    \n",
    "  def __getitem__(self, index):\n",
    "    x = torch.FloatTensor([self.x[index] ** 2, self.x[index]])\n",
    "    y = torch.FloatTensor([self.y[index]])\n",
    "    return x, y\n",
    "  \n",
    "  def __len__(self):\n",
    "    return self.length\n",
    "    \n",
    "class CustomModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layer = nn.Linear(2, 1)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = self.layer(x)\n",
    "    return x\n",
    "    \n",
    "train_dataset = CustomDataset('../dataset/non_linear.csv')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 128, shuffle=True, drop_last=True)\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "model = CustomModel().to(device)\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001)\n",
    "\n",
    "for epoch in range(10000):\n",
    "  cost = 0.0\n",
    "  \n",
    "  for x, y in train_dataloader:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    \n",
    "    output = model(x)\n",
    "    loss = criterion(output, y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    cost += loss\n",
    "  cost = cost / len(train_dataloader)\n",
    "  \n",
    "  if(epoch+1) % 1000 == 0:\n",
    "    print(f'epoch: {epoch + 1:4d}, model : {list(model.parameters())}, cost: {cost:.3f}')\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
