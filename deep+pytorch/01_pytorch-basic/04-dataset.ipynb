{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset & Dataloader\n",
    "> 데이터세트는 데이터의 집합을 의미하며, 입력값(X)와 결과값(Y)에 대한 정보를 제공하거나 일련의 데이터 묶음을 제공한다.\n",
    "\n",
    "## 데이터세트 클래스 기본형\n",
    "\n",
    "- 초기화 메서드( __init__ ): 입력된 데이터의 전처리 과정을 수행\n",
    "\n",
    "- 호출 메서드( __getitem__ ): 학습을 진행할 때 사용되는 하나의 행을 불러오는 과정\n",
    "\n",
    "- 길이 반환 메서드( __len__ ): 학습에 사용된 전체 데이터세트의 개수를 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "  def __init__(self, data, *arg, **kwargs):\n",
    "    self.data = data\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    return tuple(data[index] for data in data.tensor)\n",
    "  \n",
    "  def __len__(self):\n",
    "    return self.data[0].size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader\n",
    "> Dataset에 저장된 데이터를 어떠한 방식으로 불러와 활용할지 정의한다.\n",
    "\n",
    "### 제공\n",
    "- 배치 크기(batch_size): 학습에 사용되는 데이터의 개수가 많이 한 번의 엑포에서 모든 데이터를 메모리에 올릴 수 없을 때 데이터를 나누는 역할을 수행한다.\n",
    "- 데이터 순서 변경(shuffle): 모델이 데이터 간의 관계가 아닌, 데이터의 순서로 학습되는 것을 방지하고자 수행\n",
    "- 데이터 로드 프로세스 수(num_workers): 데이터를 불러올 때 사용할 프로세스의 개수를 의미한다.\n",
    "\n",
    "## 다중 선형 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000 | Model [Parameter containing:\n",
      "tensor([[ 1.0914, -0.3564],\n",
      "        [ 0.5474,  0.6114]], requires_grad=True), Parameter containing:\n",
      "tensor([0.2514, 0.1837], requires_grad=True)] | Cost: 0.082\n",
      "Epoch 2000 | Model [Parameter containing:\n",
      "tensor([[ 1.2589, -0.4431],\n",
      "        [ 0.6909,  0.5371]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0028, -0.0340], requires_grad=True)] | Cost: 0.021\n",
      "Epoch 3000 | Model [Parameter containing:\n",
      "tensor([[ 1.3444, -0.4872],\n",
      "        [ 0.7640,  0.4994]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.1324, -0.1449], requires_grad=True)] | Cost: 0.006\n",
      "Epoch 4000 | Model [Parameter containing:\n",
      "tensor([[ 1.3879, -0.5097],\n",
      "        [ 0.8012,  0.4801]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.1984, -0.2014], requires_grad=True)] | Cost: 0.001\n",
      "Epoch 5000 | Model [Parameter containing:\n",
      "tensor([[ 1.4100, -0.5212],\n",
      "        [ 0.8202,  0.4703]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.2320, -0.2302], requires_grad=True)] | Cost: 0.000\n",
      "Epoch 6000 | Model [Parameter containing:\n",
      "tensor([[ 1.4213, -0.5270],\n",
      "        [ 0.8299,  0.4653]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.2491, -0.2449], requires_grad=True)] | Cost: 0.000\n",
      "Epoch 7000 | Model [Parameter containing:\n",
      "tensor([[ 1.4271, -0.5300],\n",
      "        [ 0.8348,  0.4627]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.2579, -0.2523], requires_grad=True)] | Cost: 0.000\n",
      "Epoch 8000 | Model [Parameter containing:\n",
      "tensor([[ 1.4300, -0.5315],\n",
      "        [ 0.8373,  0.4614]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.2623, -0.2561], requires_grad=True)] | Cost: 0.000\n",
      "Epoch 9000 | Model [Parameter containing:\n",
      "tensor([[ 1.4315, -0.5323],\n",
      "        [ 0.8386,  0.4608]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.2646, -0.2581], requires_grad=True)] | Cost: 0.000\n",
      "Epoch 10000 | Model [Parameter containing:\n",
      "tensor([[ 1.4323, -0.5327],\n",
      "        [ 0.8392,  0.4604]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.2657, -0.2591], requires_grad=True)] | Cost: 0.000\n",
      "Epoch 11000 | Model [Parameter containing:\n",
      "tensor([[ 1.4327, -0.5329],\n",
      "        [ 0.8396,  0.4603]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.2663, -0.2596], requires_grad=True)] | Cost: 0.000\n",
      "Epoch 12000 | Model [Parameter containing:\n",
      "tensor([[ 1.4329, -0.5330],\n",
      "        [ 0.8397,  0.4602]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.2666, -0.2598], requires_grad=True)] | Cost: 0.000\n",
      "Epoch 13000 | Model [Parameter containing:\n",
      "tensor([[ 1.4330, -0.5330],\n",
      "        [ 0.8398,  0.4601]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.2668, -0.2600], requires_grad=True)] | Cost: 0.000\n",
      "Epoch 14000 | Model [Parameter containing:\n",
      "tensor([[ 1.4330, -0.5330],\n",
      "        [ 0.8399,  0.4601]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.2669, -0.2600], requires_grad=True)] | Cost: 0.000\n",
      "Epoch 15000 | Model [Parameter containing:\n",
      "tensor([[ 1.4330, -0.5330],\n",
      "        [ 0.8399,  0.4601]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.2669, -0.2601], requires_grad=True)] | Cost: 0.000\n",
      "Epoch 16000 | Model [Parameter containing:\n",
      "tensor([[ 1.4330, -0.5330],\n",
      "        [ 0.8399,  0.4601]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.2669, -0.2601], requires_grad=True)] | Cost: 0.000\n",
      "Epoch 17000 | Model [Parameter containing:\n",
      "tensor([[ 1.4330, -0.5330],\n",
      "        [ 0.8399,  0.4601]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.2669, -0.2601], requires_grad=True)] | Cost: 0.000\n",
      "Epoch 18000 | Model [Parameter containing:\n",
      "tensor([[ 1.4330, -0.5330],\n",
      "        [ 0.8399,  0.4601]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.2669, -0.2601], requires_grad=True)] | Cost: 0.000\n",
      "Epoch 19000 | Model [Parameter containing:\n",
      "tensor([[ 1.4330, -0.5330],\n",
      "        [ 0.8399,  0.4601]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.2669, -0.2601], requires_grad=True)] | Cost: 0.000\n",
      "Epoch 20000 | Model [Parameter containing:\n",
      "tensor([[ 1.4330, -0.5330],\n",
      "        [ 0.8399,  0.4601]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.2669, -0.2601], requires_grad=True)] | Cost: 0.000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_x = torch.FloatTensor([\n",
    "  [1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7]\n",
    "])\n",
    "train_y = torch.FloatTensor([\n",
    "  [0.1, 1.5], [1, 2.8], [1.9, 4.1], [2.8, 5.4], [3.7, 6.7], [4.6, 8]\n",
    "])\n",
    "\n",
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "train_dataLoader = DataLoader(train_dataset, batch_size = 2, shuffle= True, drop_last= True)\n",
    "# drop_last = True : 배치 크기에 맞지 않는 배치를 제거한다. 예를 들어, 데이터세트의 크기가 5일 때, 배치사이즈가 2라면 마지막 배치의 크기는 1이 된다. 1인 마지막 배치를 학습에 포함시키지 않는다.\n",
    "\n",
    "# 모델, 오차함수, 최적화 선언\n",
    "model = nn.Linear(2, 2, bias = True)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001)\n",
    "\n",
    "# 데이터로더 적용\n",
    "for epoch in range(20000):\n",
    "  cost = 0.0\n",
    "  \n",
    "  for batch in train_dataLoader:\n",
    "    x, y = batch\n",
    "    output = model(x)\n",
    "    \n",
    "    loss = criterion(output, y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    cost += loss\n",
    "  \n",
    "  cost = cost / len(train_dataLoader)\n",
    "  \n",
    "  if(epoch + 1) % 1000 == 0:\n",
    "    print(f'Epoch {epoch + 1:4d} | Model {list(model.parameters())} | Cost: {cost:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 / 데이터세트 분리\n",
    "\n",
    "## 모듈 클래스\n",
    "> 초기화 메서드와 순방향 메서드를 재정의하여 활용한다. 초기화 메서드는 신경망에 사용될 계층을 초기화하고, 순방향 메서드에서는 모델이 어떤 구조를 갖게 될지를 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 클래스 기본형\n",
    "class Model(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__() # 모듈 클래스의 속성을 초기화\n",
    "    self.conv1 = nn.Conv2d(1, 20, 5)\n",
    "    self.conv2 = nn.Conv2d(20, 20, 5)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.conv1(x))\n",
    "    x = F.relu(self.conv2(x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1000, model : [Parameter containing:\n",
      "tensor([[ 3.1107, -1.7002]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([-0.1488], device='mps:0', requires_grad=True)], cost: 0.222\n",
      "epoch: 2000, model : [Parameter containing:\n",
      "tensor([[ 3.1097, -1.7028]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([-0.0942], device='mps:0', requires_grad=True)], cost: 0.199\n",
      "epoch: 3000, model : [Parameter containing:\n",
      "tensor([[ 3.1089, -1.7026]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([-0.0442], device='mps:0', requires_grad=True)], cost: 0.196\n",
      "epoch: 4000, model : [Parameter containing:\n",
      "tensor([[ 3.1081, -1.7027]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.0017], device='mps:0', requires_grad=True)], cost: 0.171\n",
      "epoch: 5000, model : [Parameter containing:\n",
      "tensor([[ 3.1077, -1.7028]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.0435], device='mps:0', requires_grad=True)], cost: 0.168\n",
      "epoch: 6000, model : [Parameter containing:\n",
      "tensor([[ 3.1067, -1.7029]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.0818], device='mps:0', requires_grad=True)], cost: 0.152\n",
      "epoch: 7000, model : [Parameter containing:\n",
      "tensor([[ 3.1062, -1.7027]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.1169], device='mps:0', requires_grad=True)], cost: 0.134\n",
      "epoch: 8000, model : [Parameter containing:\n",
      "tensor([[ 3.1059, -1.7030]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.1490], device='mps:0', requires_grad=True)], cost: 0.127\n",
      "epoch: 9000, model : [Parameter containing:\n",
      "tensor([[ 3.1049, -1.7029]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.1783], device='mps:0', requires_grad=True)], cost: 0.127\n",
      "epoch: 10000, model : [Parameter containing:\n",
      "tensor([[ 3.1045, -1.7030]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.2052], device='mps:0', requires_grad=True)], cost: 0.102\n"
     ]
    }
   ],
   "source": [
    "# 비선형 회귀\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    self.x = df.iloc[:, 0].values\n",
    "    self.y = df.iloc[:, 1].values\n",
    "    self.length = len(df)\n",
    "    \n",
    "  def __getitem__(self, index):\n",
    "    x = torch.FloatTensor([self.x[index] ** 2, self.x[index]])\n",
    "    y = torch.FloatTensor([self.y[index]])\n",
    "    return x, y\n",
    "  \n",
    "  def __len__(self):\n",
    "    return self.length\n",
    "    \n",
    "class CustomModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layer = nn.Linear(2, 1)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = self.layer(x)\n",
    "    return x\n",
    "    \n",
    "train_dataset = CustomDataset('../dataset/non_linear.csv')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 128, shuffle=True, drop_last=True)\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "model = CustomModel().to(device)\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001)\n",
    "\n",
    "for epoch in range(10000):\n",
    "  cost = 0.0\n",
    "  \n",
    "  for x, y in train_dataloader:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    \n",
    "    output = model(x)\n",
    "    loss = criterion(output, y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    cost += loss\n",
    "  cost = cost / len(train_dataloader)\n",
    "  \n",
    "  if(epoch+1) % 1000 == 0:\n",
    "    print(f'epoch: {epoch + 1:4d}, model : {list(model.parameters())}, cost: {cost:.3f}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.6067],\n",
      "        [69.3025],\n",
      "        [49.7713]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "from torch import no_grad\n",
    "with no_grad():\n",
    "  model.eval()\n",
    "  inputs = torch.FloatTensor(\n",
    "    [\n",
    "      [1 ** 2, 1],\n",
    "      [5 ** 2, 5],\n",
    "      [11 * 2, 11]\n",
    "    ]\n",
    "  ).to(device)\n",
    "  output = model(inputs)\n",
    "  print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "  model,\n",
    "  \"./models/model.pt\"\n",
    ")\n",
    "torch.save(\n",
    "  model.state_dict(),\n",
    "  \"./models/model_state_dice.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터세트 분리\n",
    "> 머신러닝에서 사용되는 전체 데이터세트는 두 가지 쪼는 세 가지로 나눌 수 있다. 전체 데이터 세트는 훈련용 데이터, 테스트 데이터로 분류되고 세분화 하면 검즘용 데이터 까지 분리해 활용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Size : 160\n",
      "Validation Data Size : 20\n",
      "Test Data Size : 20\n",
      "epoch: 1000, model : [Parameter containing:\n",
      "tensor([[ 3.1016, -1.7038]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4096], device='mps:0', requires_grad=True)], cost: 0.080\n",
      "epoch: 2000, model : [Parameter containing:\n",
      "tensor([[ 3.1022, -1.7039]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4672], device='mps:0', requires_grad=True)], cost: 0.076\n",
      "epoch: 3000, model : [Parameter containing:\n",
      "tensor([[ 3.0997, -1.7040]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4898], device='mps:0', requires_grad=True)], cost: 0.075\n",
      "epoch: 4000, model : [Parameter containing:\n",
      "tensor([[ 3.0993, -1.7039]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.4987], device='mps:0', requires_grad=True)], cost: 0.077\n",
      "epoch: 5000, model : [Parameter containing:\n",
      "tensor([[ 3.0991, -1.7039]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.5021], device='mps:0', requires_grad=True)], cost: 0.076\n",
      "epoch: 6000, model : [Parameter containing:\n",
      "tensor([[ 3.1000, -1.7041]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.5036], device='mps:0', requires_grad=True)], cost: 0.077\n",
      "epoch: 7000, model : [Parameter containing:\n",
      "tensor([[ 3.0994, -1.7041]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.5040], device='mps:0', requires_grad=True)], cost: 0.074\n",
      "epoch: 8000, model : [Parameter containing:\n",
      "tensor([[ 3.0993, -1.7040]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.5043], device='mps:0', requires_grad=True)], cost: 0.076\n",
      "epoch: 9000, model : [Parameter containing:\n",
      "tensor([[ 3.0997, -1.7041]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.5043], device='mps:0', requires_grad=True)], cost: 0.075\n",
      "epoch: 10000, model : [Parameter containing:\n",
      "tensor([[ 3.1007, -1.7040]], device='mps:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.5043], device='mps:0', requires_grad=True)], cost: 0.076\n",
      "X : tensor([90.2500,  9.5000], device='mps:0'), Y : tensor([263.8000], device='mps:0'), Predict : tensor([264.1551], device='mps:0')\n",
      "X : tensor([70.5600, -8.4000], device='mps:0'), Y : tensor([233.6700], device='mps:0'), Predict : tensor([233.6031], device='mps:0')\n",
      "X : tensor([38.4400, -6.2000], device='mps:0'), Y : tensor([130.4100], device='mps:0'), Predict : tensor([130.2598], device='mps:0')\n",
      "X : tensor([33.6400, -5.8000], device='mps:0'), Y : tensor([114.6200], device='mps:0'), Predict : tensor([114.6949], device='mps:0')\n",
      "X : tensor([10.8900, -3.3000], device='mps:0'), Y : tensor([39.7100], device='mps:0'), Predict : tensor([39.8940], device='mps:0')\n",
      "X : tensor([ 0.0400, -0.2000], device='mps:0'), Y : tensor([1.0400], device='mps:0'), Predict : tensor([0.9691], device='mps:0')\n",
      "X : tensor([37.2100,  6.1000], device='mps:0'), Y : tensor([105.9800], device='mps:0'), Predict : tensor([105.4873], device='mps:0')\n",
      "X : tensor([25.,  5.], device='mps:0'), Y : tensor([69.6700], device='mps:0'), Predict : tensor([69.5021], device='mps:0')\n",
      "X : tensor([67.2400,  8.2000], device='mps:0'), Y : tensor([195.2000], device='mps:0'), Predict : tensor([195.0231], device='mps:0')\n",
      "X : tensor([56.2500, -7.5000], device='mps:0'), Y : tensor([187.6300], device='mps:0'), Predict : tensor([187.6985], device='mps:0')\n",
      "X : tensor([46.2400,  6.8000], device='mps:0'), Y : tensor([132.0400], device='mps:0'), Predict : tensor([132.2939], device='mps:0')\n",
      "X : tensor([81.,  9.], device='mps:0'), Y : tensor([236.7600], device='mps:0'), Predict : tensor([236.3255], device='mps:0')\n",
      "X : tensor([88.3600,  9.4000], device='mps:0'), Y : tensor([258.9200], device='mps:0'), Predict : tensor([258.4651], device='mps:0')\n",
      "X : tensor([30.2500,  5.5000], device='mps:0'), Y : tensor([85.2600], device='mps:0'), Predict : tensor([84.9288], device='mps:0')\n",
      "X : tensor([46.2400, -6.8000], device='mps:0'), Y : tensor([155.4300], device='mps:0'), Predict : tensor([155.4677], device='mps:0')\n",
      "X : tensor([10.8900,  3.3000], device='mps:0'), Y : tensor([28.5400], device='mps:0'), Predict : tensor([28.6479], device='mps:0')\n",
      "X : tensor([0.0900, 0.3000], device='mps:0'), Y : tensor([0.2700], device='mps:0'), Predict : tensor([0.2722], device='mps:0')\n",
      "X : tensor([9.6100, 3.1000], device='mps:0'), Y : tensor([25.0400], device='mps:0'), Predict : tensor([25.0198], device='mps:0')\n",
      "X : tensor([27.0400,  5.2000], device='mps:0'), Y : tensor([75.1200], device='mps:0'), Predict : tensor([75.4867], device='mps:0')\n",
      "X : tensor([44.8900,  6.7000], device='mps:0'), Y : tensor([127.8900], device='mps:0'), Predict : tensor([128.2783], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "dataset = CustomDataset('../dataset/non_linear.csv')\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(dataset_size * 0.8)\n",
    "validation_size = int(dataset_size * 0.1)\n",
    "test_size = dataset_size - train_size - validation_size\n",
    "\n",
    "train_dataset, validation_dataset, test_dataset = random_split(dataset, [train_size, validation_size, test_size])\n",
    "print(f\"Training Data Size : {len(train_dataset)}\")\n",
    "print(f\"Validation Data Size : {len(validation_dataset)}\")\n",
    "print(f\"Test Data Size : {len(test_dataset)}\")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, drop_last=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=16, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True, drop_last=True)\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "model = CustomModel().to(device)\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001)\n",
    "\n",
    "for epoch in range(10000):\n",
    "  cost = 0.0\n",
    "  \n",
    "  for x, y in train_dataloader:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    \n",
    "    output = model(x)\n",
    "    loss = criterion(output, y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    cost += loss\n",
    "  cost = cost / len(train_dataloader)\n",
    "  \n",
    "  if(epoch+1) % 1000 == 0:\n",
    "    print(f'epoch: {epoch + 1:4d}, model : {list(model.parameters())}, cost: {cost:.3f}')\n",
    "    \n",
    "with no_grad():\n",
    "  model.eval()\n",
    "  for x, y in validation_dataset:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    \n",
    "    output = model(x)    \n",
    "    print(f\"X : {x}, Y : {y}, Predict : {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 저장 및 불러오기\n",
    "> 파이토치 모델은 직렬화(Serialize)와 역직렬화(Deserialize)를 통해 객체를 저장하고 불러올 수 있다.\n",
    "\n",
    "- 모델을 저장하려면 파이썬의 'Pickle'을 활용해 파이썬 객체 구조를 바이너리 프로토콜(Binary Protocols)로 직렬화 한다. \n",
    "- 모델을 불러오려면 저장된 객체 파일을 역직렬화해 현재 프로세스의 메모리에 업로드한다.\n",
    "\n",
    "#### 모델 저장\n",
    "```python\n",
    "torch.save(\n",
    "  model,\n",
    "  path\n",
    ")\n",
    "```\n",
    "\n",
    "#### 모델 불러오기\n",
    "```python\n",
    "torch.load(\n",
    "  path,\n",
    "  map_location\n",
    ")\n",
    "```\n",
    "- `map_location` : 모델을 불러올 때 적용하려는 장치 상태를 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomModel(\n",
      "  (layer): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n",
      "tensor([[ 1.6067],\n",
      "        [69.3025],\n",
      "        [49.7713]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\"./models/model.pt\", map_location=device)\n",
    "print(model)\n",
    "\n",
    "with torch.no_grad():\n",
    "  model.eval()\n",
    "  inputs = torch.FloatTensor(\n",
    "    [\n",
    "      [1 ** 2, 1],\n",
    "      [5 ** 2, 5],\n",
    "      [11 * 2, 11]\n",
    "    ]\n",
    "  ).to(device)\n",
    "  output = model(inputs)\n",
    "  print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomModel(\n",
      "  (layer): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델 구조 확인하기\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "  pass\n",
    "\n",
    "model = torch.load(\"./models/model.pt\", map_location=device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 상태 저장 및 불러오기\n",
    "> 모델 전체를 저장하면 모델의 모든 모든 정보를 저장하므로 모델 상태만 저장하는 것보다 더 많은 저장공간이 필요하다. 그러므로 모델의 매개변수만 저장하여 활용하는 방법을 사용할 수 있다.\n",
    "\n",
    "```python\n",
    "torch.save(\n",
    "  model.state_dict(),\n",
    "  path\n",
    ")\n",
    "```\n",
    "> 이러한 방식으로 저장된 모델에는 학습된 CustomModel 객체의 가중치와 편향이 저장돼 있다. 즉, 추론에 필요한 데이터만 가져와 저장하는 방식으로 이해할 수 있다.\n",
    "\n",
    "### 체크포인트\n",
    "> 체크포인트는 학습 과정의 특정 지점마다 저장하는 것을 의미한다. 학습 시 예기치 못하게 오류가 발생하거나 시스템 리소스 과부하 등으로 학습니 정상적으로 마무리 되지 않을경우 활용할 수 있다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
