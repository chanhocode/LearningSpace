{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 퍼셉트론 (Perceptron)\n",
    "> 인공신경망의 한 종류로서, 출력이 0 또는 1인 작업을 의미하는 이진 분류 작업에 사용되는 간단한 모델이다. 페셉트론은 신경 세포(Neuron)가 신호를 전달하는 구조와 유사한 방식으로 구현됐다.\n",
    "\n",
    "## 단층 퍼셉트론(Single Layer Perceptron)\n",
    "> 입력을 통해 데이터가 전달되고, 입력값은 각각의 가중치와 함께 노드에 전달된다. 전달된 입력값과 가중치를 곱합 값이 활성화 함수에 전달된다. 활성화 함수에서 출력값이 계산되고 이 값을 손실함수에 실제값과 함께 연산해 가중치를 변경한다.\n",
    "\n",
    "- `단층 퍼셉트론의 한계`: AND, OR, NAND 게이트와 같은 구조를 갖는 모델은 쉽게 구현하지만 XOR 게이트처럼 하나의 기울기로 표현하기 어려운 구조에서는 적응이 어렵다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2y/2cp_6ft96fn709961nxvzc8h0000gn/T/ipykernel_36169/2278278290.py:18: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  x = torch.FloatTensor([self.x1[index], self.x2[index]])\n",
      "/var/folders/2y/2cp_6ft96fn709961nxvzc8h0000gn/T/ipykernel_36169/2278278290.py:19: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  y = torch.FloatTensor([self.y[index]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000, Cost: 0.692743\n",
      "Epoch: 2000, Cost: 0.691857\n",
      "Epoch: 3000, Cost: 0.692155\n",
      "Epoch: 4000, Cost: 0.692033\n",
      "Epoch: 5000, Cost: 0.691577\n",
      "Epoch: 6000, Cost: 0.692609\n",
      "Epoch: 7000, Cost: 0.691862\n",
      "Epoch: 8000, Cost: 0.691921\n",
      "Epoch: 9000, Cost: 0.691986\n",
      "Epoch: 10000, Cost: 0.691038\n",
      "--------------------------------\n",
      "tensor([[0.4672],\n",
      "        [0.4998],\n",
      "        [0.5030],\n",
      "        [0.5356]], device='mps:0')\n",
      "tensor([[ True],\n",
      "        [ True],\n",
      "        [False],\n",
      "        [False]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋에서 x1, x2는 입력값, y는 XOR 게이트를 통과했을 때의 결과를 의미\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    self.x1 = df.iloc[:, 0].values\n",
    "    self.x2 = df.iloc[:, 1].values\n",
    "    self.y = df.iloc[:, 2].values\n",
    "    self.length = len(df)\n",
    "    \n",
    "  def __getitem__(self, index):\n",
    "    x = torch.FloatTensor([self.x1[index], self.x2[index]])\n",
    "    y = torch.FloatTensor([self.y[index]])\n",
    "    return x, y\n",
    "  \n",
    "  def __len__(self):\n",
    "    return self.length\n",
    "    \n",
    "class CustomModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.layer = nn.Sequential(\n",
    "      nn.Linear(2,1),\n",
    "      nn.Sigmoid()\n",
    "    )\n",
    "  def forward(self, x):\n",
    "    x = self.layer(x)\n",
    "    return x\n",
    "  \n",
    "train_dataset = CustomDataset('../dataset/perceptron.csv')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=True)\n",
    "\n",
    "device = 'mps'\n",
    "model = CustomModel().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(10000):\n",
    "  cost = 0.0\n",
    "  \n",
    "  for x, y in train_dataloader:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    \n",
    "    output = model(x)\n",
    "    loss = criterion(output, y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    cost += loss\n",
    "  cost = cost / len(train_dataloader)\n",
    "  \n",
    "  if (epoch + 1) % 1000 == 0:\n",
    "    print(f'Epoch: {epoch + 1:04d}, Cost: {cost:.6f}')\n",
    "    \n",
    "with torch.no_grad():\n",
    "  model.eval()\n",
    "  inputs = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "  outputs = model(inputs)\n",
    "  \n",
    "  print(\"--------------------------------\")\n",
    "  print(outputs)\n",
    "  print(outputs <= 0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다층 퍼셉트론(Multi_Layer Perceptron, MLP)\n",
    "> 단층 퍼셉트론을 여러 개 쌓아 은닉층을 생성한다. 은닉층을 2개 이상 연결하면 심층 신경망 이라 부른다. 계층이 많으면 더 정확한 값을 찾을 수 있다. 하지만 계층이 늘어날수록 갱신해야 하는 가중치나 편향이 늘어난다. 최적의 가중치와 편향을 찾기 위해 많은 학습 데이터와 연산량을 필요로 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2y/2cp_6ft96fn709961nxvzc8h0000gn/T/ipykernel_36169/2278278290.py:18: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  x = torch.FloatTensor([self.x1[index], self.x2[index]])\n",
      "/var/folders/2y/2cp_6ft96fn709961nxvzc8h0000gn/T/ipykernel_36169/2278278290.py:19: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  y = torch.FloatTensor([self.y[index]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000, Cost: 0.693472\n",
      "Epoch: 2000, Cost: 0.693049\n",
      "Epoch: 3000, Cost: 0.689960\n",
      "Epoch: 4000, Cost: 0.622948\n",
      "Epoch: 5000, Cost: 0.488062\n",
      "Epoch: 6000, Cost: 0.099369\n",
      "Epoch: 7000, Cost: 0.041701\n",
      "Epoch: 8000, Cost: 0.025805\n",
      "Epoch: 9000, Cost: 0.018531\n",
      "Epoch: 10000, Cost: 0.014431\n",
      "--------------------------------\n",
      "tensor([[0.0164],\n",
      "        [0.9865],\n",
      "        [0.9876],\n",
      "        [0.0150]], device='mps:0')\n",
      "tensor([[ True],\n",
      "        [False],\n",
      "        [False],\n",
      "        [ True]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "class CustomModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.layer1 = nn.Sequential(\n",
    "      nn.Linear(2, 2),\n",
    "      nn.Sigmoid()\n",
    "    )\n",
    "    \n",
    "    self.layer2 = nn.Sequential(\n",
    "      nn.Linear(2, 1),\n",
    "      nn.Sigmoid()\n",
    "    )\n",
    "  def forward(self, x):\n",
    "    x = self.layer1(x)\n",
    "    x = self.layer2(x)\n",
    "    return x\n",
    "  \n",
    "model = CustomModel().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(10000):\n",
    "  cost = 0.0\n",
    "  \n",
    "  for x, y in train_dataloader:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    \n",
    "    output = model(x)\n",
    "    loss = criterion(output, y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    cost += loss\n",
    "  cost = cost / len(train_dataloader)\n",
    "  \n",
    "  if (epoch + 1) % 1000 == 0:\n",
    "    print(f'Epoch: {epoch + 1:04d}, Cost: {cost:.6f}')\n",
    "    \n",
    "with torch.no_grad():\n",
    "  model.eval()\n",
    "  inputs = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "  outputs = model(inputs)\n",
    "  \n",
    "  print(\"--------------------------------\")\n",
    "  print(outputs)\n",
    "  print(outputs <= 0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
